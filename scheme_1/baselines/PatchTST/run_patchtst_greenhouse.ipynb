{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cce60c00",
   "metadata": {},
   "source": [
    "# PatchTST Greenhouse Experiment\n",
    "\n",
    "This notebook trains and evaluates the PatchTST baseline on the greenhouse dataset, consistent with the TPLC_Net pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c7ffac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure local modules can be imported\n",
    "if str(Path.cwd()) not in sys.path:\n",
    "    sys.path.append(str(Path.cwd()))\n",
    "\n",
    "# Inject TPLC_Net path\n",
    "# Assuming notebook is in degree_code/scheme_1/baselines/PatchTST\n",
    "# And TPLC_Net is in degree_code/scheme_1/TPLC_Net\n",
    "scheme_root = Path.cwd().resolve().parent.parent.parent # scheme_1 if cwd is PatchTST\n",
    "if not (scheme_root / 'TPLC_Net').exists():\n",
    "    # Fallback if cwd is different\n",
    "    scheme_root = Path('../../../').resolve()\n",
    "    \n",
    "tplc_path = scheme_root / 'TPLC_Net'\n",
    "if str(tplc_path) not in sys.path:\n",
    "    sys.path.insert(0, str(tplc_path))\n",
    "\n",
    "# Import TPLC pipeline tools\n",
    "from tplc_algo.pipeline import prepare_greenhouse_datasets, make_loaders\n",
    "from tplc_algo.train import Trainer, TrainConfig\n",
    "from tplc_algo.utils import seed_everything\n",
    "from tplc_algo.exp_utils import (\n",
    "    create_run_dir,\n",
    "    save_config_json,\n",
    "    save_env_json,\n",
    "    save_history_csv,\n",
    "    save_metrics_json,\n",
    "    save_figure,\n",
    ")\n",
    "\n",
    "# Import PatchTST (local file)\n",
    "try:\n",
    "    from patchtst_forecaster import PatchTSTForecaster\n",
    "except ImportError:\n",
    "    # If running from a different dir, try absolute import\n",
    "    sys.path.append(str(Path.cwd()))\n",
    "    from patchtst_forecaster import PatchTSTForecaster\n",
    "\n",
    "seed_everything(42)\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e89eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Configuration ======\n",
    "dataset_root = scheme_root / 'datasets' / '自主温室挑战赛'\n",
    "team = 'AICU'\n",
    "seq_len = 288\n",
    "pred_len = 72\n",
    "stride = 1\n",
    "batch_size = 32\n",
    "\n",
    "# Model Config\n",
    "d_model = 64\n",
    "n_heads = 4\n",
    "d_ff = 128\n",
    "e_layers = 2\n",
    "factor = 3\n",
    "dropout = 0.1\n",
    "patch_len = 16\n",
    "patch_stride = 8\n",
    "\n",
    "# Training Config\n",
    "epochs = 20\n",
    "lr = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "exp_name = f\"patchtst_greenhouse_{team}_nb\"\n",
    "run_dir = create_run_dir(exp_name, base_dir=Path('./results'))\n",
    "\n",
    "print(f'Device: {device}')\n",
    "print(f'Run Dir: {run_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e484b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Data Preparation ======\n",
    "prepared = prepare_greenhouse_datasets(\n",
    "    dataset_root=dataset_root,\n",
    "    team=team,\n",
    "    seq_len=seq_len,\n",
    "    pred_len=pred_len,\n",
    "    stride=stride,\n",
    "    missing_rate_threshold=0.7,\n",
    "    drop_constant=True,\n",
    "    protect_target_cols=True,\n",
    ")\n",
    "\n",
    "train_loader, val_loader, test_loader = make_loaders(prepared, batch_size=batch_size)\n",
    "print(f\"Features: {len(prepared.feature_cols)}, Targets: {len(prepared.target_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2571fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Model Construction ======\n",
    "model = PatchTSTForecaster(\n",
    "    input_dim=len(prepared.feature_cols),\n",
    "    target_dim=len(prepared.target_cols),\n",
    "    seq_len=seq_len,\n",
    "    pred_len=pred_len,\n",
    "    d_model=d_model,\n",
    "    n_heads=n_heads,\n",
    "    d_ff=d_ff,\n",
    "    e_layers=e_layers,\n",
    "    factor=factor,\n",
    "    dropout=dropout,\n",
    "    patch_len=patch_len,\n",
    "    stride=patch_stride,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0033a37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Training ======\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    cfg=TrainConfig(\n",
    "        epochs=epochs,\n",
    "        lr=lr,\n",
    "        device=device,\n",
    "        ckpt_path=run_dir / 'checkpoints' / 'best.pt',\n",
    "        early_stop_patience=6,\n",
    "        show_progress=True\n",
    "    )\n",
    ")\n",
    "\n",
    "history = trainer.fit(train_loader, val_loader=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0716f9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Evaluation ======\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "if 'val_loss' in history:\n",
    "    plt.plot(history['val_loss'], label='Val Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss Curve')\n",
    "plt.show()\n",
    "\n",
    "metrics = trainer.evaluate(test_loader)\n",
    "\n",
    "# Inverse Transform Metrics\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_trues = []\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x = x.to(device)\n",
    "        y_hat = model(x).cpu().numpy()\n",
    "        all_preds.append(y_hat)\n",
    "        all_trues.append(y.numpy())\n",
    "\n",
    "y_hat = np.concatenate(all_preds, axis=0)\n",
    "y_true = np.concatenate(all_trues, axis=0)\n",
    "\n",
    "target_scaler = prepared.target_scaler\n",
    "y_hat_raw = target_scaler.inverse_transform(y_hat.reshape(-1, y_hat.shape[-1])).reshape(y_hat.shape)\n",
    "y_true_raw = target_scaler.inverse_transform(y_true.reshape(-1, y_true.shape[-1])).reshape(y_true.shape)\n",
    "\n",
    "metrics['mae_raw'] = float(np.mean(np.abs(y_hat_raw - y_true_raw)))\n",
    "metrics['rmse_raw'] = float(np.sqrt(np.mean((y_hat_raw - y_true_raw)**2)))\n",
    "\n",
    "print(\"Final Metrics:\", metrics)\n",
    "save_metrics_json(run_dir, metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TPLC_Net",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
