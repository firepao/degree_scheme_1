{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ab228c7",
   "metadata": {},
   "source": [
    "# Transformer Greenhouse Experiment\n",
    "\n",
    "This notebook trains and evaluates the Transformer baseline on the greenhouse dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa30391f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if str(Path.cwd()) not in sys.path:\n",
    "    sys.path.append(str(Path.cwd()))\n",
    "\n",
    "scheme_root = Path.cwd().resolve().parent.parent.parent # if cwd is Transformer\n",
    "if not (scheme_root / 'TPLC_Net').exists():\n",
    "    scheme_root = Path('../../../').resolve()\n",
    "    \n",
    "tplc_path = scheme_root / 'TPLC_Net'\n",
    "if str(tplc_path) not in sys.path:\n",
    "    sys.path.insert(0, str(tplc_path))\n",
    "\n",
    "from tplc_algo.pipeline import prepare_greenhouse_datasets, make_loaders\n",
    "from tplc_algo.train import Trainer, TrainConfig\n",
    "from tplc_algo.utils import seed_everything\n",
    "from tplc_algo.exp_utils import create_run_dir, save_metrics_json\n",
    "\n",
    "try:\n",
    "    from transformer_forecaster import TransformerForecaster\n",
    "except ImportError:\n",
    "    sys.path.append(str(Path.cwd()))\n",
    "    from transformer_forecaster import TransformerForecaster\n",
    "\n",
    "seed_everything(42)\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13639881",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = scheme_root / 'datasets' / '自主温室挑战赛'\n",
    "team = 'AICU'\n",
    "seq_len = 288\n",
    "pred_len = 72\n",
    "stride = 1\n",
    "batch_size = 32\n",
    "\n",
    "d_model = 64\n",
    "n_heads = 4\n",
    "d_ff = 128\n",
    "e_layers = 2\n",
    "d_layers = 1\n",
    "factor = 3\n",
    "dropout = 0.1\n",
    "\n",
    "epochs = 20\n",
    "lr = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "exp_name = f\"transformer_greenhouse_{team}_nb\"\n",
    "run_dir = create_run_dir(exp_name, base_dir=Path('./results'))\n",
    "print(f\"Experiment Dir: {run_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d131ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared = prepare_greenhouse_datasets(\n",
    "    dataset_root=dataset_root,\n",
    "    team=team,\n",
    "    seq_len=seq_len,\n",
    "    pred_len=pred_len,\n",
    "    stride=stride,\n",
    "    missing_rate_threshold=0.7,\n",
    "    drop_constant=True,\n",
    "    protect_target_cols=True,\n",
    ")\n",
    "train_loader, val_loader, test_loader = make_loaders(prepared, batch_size=batch_size)\n",
    "print(f\"Input Dim: {len(prepared.feature_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc34d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerForecaster(\n",
    "    input_dim=len(prepared.feature_cols),\n",
    "    target_dim=len(prepared.target_cols),\n",
    "    seq_len=seq_len,\n",
    "    pred_len=pred_len,\n",
    "    d_model=d_model,\n",
    "    n_heads=n_heads,\n",
    "    d_ff=d_ff,\n",
    "    e_layers=e_layers,\n",
    "    d_layers=d_layers,\n",
    "    factor=factor,\n",
    "    dropout=dropout,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fed5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    cfg=TrainConfig(\n",
    "        epochs=epochs,\n",
    "        lr=lr,\n",
    "        device=device,\n",
    "        ckpt_path=run_dir / 'checkpoints' / 'best.pt',\n",
    "        early_stop_patience=6,\n",
    "        show_progress=True\n",
    "    )\n",
    ")\n",
    "history = trainer.fit(train_loader, val_loader=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75178bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history['train_loss'], label='Train')\n",
    "plt.plot(history['val_loss'], label='Val')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "metrics = trainer.evaluate(test_loader)\n",
    "\n",
    "model.eval()\n",
    "preds = []\n",
    "trues = []\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x = x.to(device)\n",
    "        preds.append(model(x).cpu().numpy())\n",
    "        trues.append(y.numpy())\n",
    "        \n",
    "y_hat = np.concatenate(preds)\n",
    "y_true = np.concatenate(trues)\n",
    "scaler = prepared.target_scaler\n",
    "y_hat_raw = scaler.inverse_transform(y_hat.reshape(-1, y_hat.shape[-1])).reshape(y_hat.shape)\n",
    "y_true_raw = scaler.inverse_transform(y_true.reshape(-1, y_true.shape[-1])).reshape(y_true.shape)\n",
    "\n",
    "metrics['mae_raw'] = float(np.mean(np.abs(y_hat_raw - y_true_raw)))\n",
    "metrics['rmse_raw'] = float(np.sqrt(np.mean((y_hat_raw - y_true_raw)**2)))\n",
    "\n",
    "print(metrics)\n",
    "save_metrics_json(run_dir, metrics)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
