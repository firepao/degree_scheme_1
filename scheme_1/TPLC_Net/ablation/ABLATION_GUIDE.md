# TPLC æ¨¡å‹æ¶ˆèå®éªŒæŒ‡å—

## ğŸ“‹ ç›®å½•
- [ä»€ä¹ˆæ˜¯æ¶ˆèå®éªŒ](#ä»€ä¹ˆæ˜¯æ¶ˆèå®éªŒ)
- [å½“å‰æ¨¡å‹çŠ¶æ€](#å½“å‰æ¨¡å‹çŠ¶æ€)
- [å·²å®ç°çš„æ”¹è¿›](#å·²å®ç°çš„æ”¹è¿›)
- [æ¶ˆèå®éªŒé…ç½®](#æ¶ˆèå®éªŒé…ç½®)
- [å®éªŒç»“æœ](#å®éªŒç»“æœ)
- [å¦‚ä½•è¿è¡Œ](#å¦‚ä½•è¿è¡Œ)
- [è¿›ä¸€æ­¥æ”¹è¿›å»ºè®®](#è¿›ä¸€æ­¥æ”¹è¿›å»ºè®®)

---

## ä»€ä¹ˆæ˜¯æ¶ˆèå®éªŒ

**æ¶ˆèå®éªŒ (Ablation Study)** æ˜¯æ·±åº¦å­¦ä¹ ä¸­éªŒè¯æ¨¡å‹å„ç»„ä»¶æœ‰æ•ˆæ€§çš„æ ‡å‡†æ–¹æ³•ï¼š

### æ ¸å¿ƒæ€æƒ³
é€šè¿‡ **é€æ­¥æ·»åŠ /ç§»é™¤** æ¨¡å‹çš„æŸä¸ªç»„ä»¶ï¼Œè§‚å¯Ÿæ€§èƒ½å˜åŒ–ï¼Œä»è€Œï¼š
1. âœ… **éªŒè¯æ”¹è¿›çš„æœ‰æ•ˆæ€§**ï¼šæ¯ä¸ªç»„ä»¶æ˜¯å¦çœŸçš„æœ‰ç”¨
2. âœ… **é‡åŒ–è´¡çŒ®**ï¼šå„ç»„ä»¶å¯¹æ€§èƒ½æå‡çš„å…·ä½“è´¡çŒ®
3. âœ… **å‘ç°å†—ä½™**ï¼šå“ªäº›ç»„ä»¶å¯ä»¥ç®€åŒ–æˆ–ç§»é™¤
4. âœ… **æŒ‡å¯¼ä¼˜åŒ–**ï¼šå“ªäº›ç»„ä»¶å€¼å¾—è¿›ä¸€æ­¥ä¼˜åŒ–

### å…¸å‹å®éªŒè®¾è®¡
```
Baseline (åŸºçº¿)
â”œâ”€â”€ + RevIN (å½’ä¸€åŒ–)
â”œâ”€â”€ + Inception Block (æ›´å¼ºçš„ç‰¹å¾æå–)
â”œâ”€â”€ + åˆ†è§£ (å­£èŠ‚-è¶‹åŠ¿åˆ†è§£)
â”œâ”€â”€ + å¤šå±‚å †å  (æ›´æ·±çš„ç½‘ç»œ)
â””â”€â”€ Full (æ‰€æœ‰æ”¹è¿›)
```

---

## å½“å‰æ¨¡å‹çŠ¶æ€

### âœ… ä½ ç°åœ¨è¿è¡Œçš„ TPLC æ¨¡å‹æ˜¯ **æ”¹è¿›åçš„ç‰ˆæœ¬**

é€šè¿‡æŸ¥çœ‹ä»£ç  (`tplc_algo/models/tplc_model.py`)ï¼Œå½“å‰æ¨¡å‹å·²ç»åŒ…å«ä»¥ä¸‹æ”¹è¿›ï¼š

#### 1. **Dropout æ­£åˆ™åŒ–** âœ…
```python
# ç¬¬ 76-77 è¡Œ
self.dropout = nn.Dropout(p=0.1)

# ç¬¬ 132 è¡Œï¼šåœ¨å¤šå‘¨æœŸèåˆå
fused = self.dropout(fused)

# ç¬¬ 149 è¡Œï¼šåœ¨é¢„æµ‹å¤´ä¸­
pred_hidden = self.dropout(pred_hidden)
```

**ä½œç”¨**ï¼šé˜²æ­¢è¿‡æ‹Ÿåˆï¼Œæå‡æ³›åŒ–èƒ½åŠ›

#### 2. **æ®‹å·®è¿æ¥ (Residual Connection)** âœ…
```python
# ç¬¬ 79-82 è¡Œï¼šæ®‹å·®æŠ•å½±å±‚
self.residual_proj = None
if self.input_dim != self.target_dim:
    self.residual_proj = nn.Linear(self.input_dim, self.target_dim)

# ç¬¬ 156-169 è¡Œï¼šæ®‹å·®è¿æ¥å®ç°
x_residual = x  # ä¿å­˜åŸå§‹è¾“å…¥
# ... ä¸»å¹²ç½‘ç»œå¤„ç† ...
y_sum = y_sum + x_res  # æ·»åŠ æ®‹å·®
```

**ä½œç”¨**ï¼š
- ç¼“è§£æ¢¯åº¦æ¶ˆå¤±é—®é¢˜
- å‚è€ƒ TimesNet çš„æˆåŠŸç»éªŒ
- ä¿ç•™è¾“å…¥çš„ä½é¢‘ä¿¡æ¯

#### 3. **è®­ç»ƒç¨³å®šæ€§é…ç½®** âœ…
åœ¨ `run_compare_experiment.ipynb` å’Œ `run_all_baselines.py` ä¸­ï¼š
```python
grad_clip_max_norm = 1.0      # æ¢¯åº¦è£å‰ª
use_amp = True                 # æ··åˆç²¾åº¦è®­ç»ƒ
lr_scheduler = 'plateau'       # å­¦ä¹ ç‡è°ƒåº¦
plateau_patience = 3           # Plateau è€å¿ƒå€¼
early_stop_patience = 6        # æ—©åœ
epochs = 20                    # å……è¶³çš„è®­ç»ƒè½®æ•°
```

### ğŸ“Š æ”¹è¿›å‰ vs æ”¹è¿›åå¯¹æ¯”

| ç‰ˆæœ¬ | MAE | RMSE | ç‰¹ç‚¹ |
|------|-----|------|------|
| **æ”¹è¿›å‰** | æœªæµ‹è¯• | æœªæµ‹è¯• | æ—  Dropoutã€æ— æ®‹å·®ã€è®­ç»ƒä¸ç¨³å®š |
| **æ”¹è¿›å** | 0.710 | 0.907 | + Dropout + æ®‹å·® + è®­ç»ƒç¨³å®šæ€§é…ç½® |

---

## å·²å®ç°çš„æ”¹è¿›

### æ ¸å¿ƒæ”¹è¿›åˆ—è¡¨

#### âœ… å·²å®ç°ï¼ˆåœ¨ä¸»æ¨¡å‹ä¸­ï¼‰
1. **Dropout æ­£åˆ™åŒ–** - é˜²æ­¢è¿‡æ‹Ÿåˆ
2. **æ®‹å·®è¿æ¥** - æå‡æ¢¯åº¦æµåŠ¨
3. **ç»´åº¦è‡ªé€‚åº”æŠ•å½±** - å¤„ç†è¾“å…¥è¾“å‡ºç»´åº¦ä¸åŒ¹é…
4. **è®­ç»ƒç¨³å®šæ€§** - æ¢¯åº¦è£å‰ªã€å­¦ä¹ ç‡è°ƒåº¦ã€æ—©åœ

#### ğŸ”„ å¯é€‰é…ç½®ï¼ˆåœ¨æ¶ˆèå®éªŒä¸­ï¼‰
5. **RevIN å½’ä¸€åŒ–** - å®ä¾‹å½’ä¸€åŒ–ï¼Œæå‡æ³›åŒ–
6. **Inception Block** - å¤šå°ºåº¦å·ç§¯æ ¸
7. **å­£èŠ‚-è¶‹åŠ¿åˆ†è§£** - æ˜¾å¼å»ºæ¨¡å‘¨æœŸæ€§
8. **å¤šå±‚å †å ** - å¢åŠ æ¨¡å‹æ·±åº¦

---

## æ¶ˆèå®éªŒé…ç½®

### é¢„å®šä¹‰é…ç½® (åœ¨ `run_ablation.py` ä¸­)

| é…ç½®åç§° | æè¿° | åŒ…å«ç»„ä»¶ |
|---------|------|---------|
| `baseline` | åŸºçº¿æ¨¡å‹ | ä»…æ ¸å¿ƒ TPLC æ¶æ„ |
| `+revin` | + RevIN | baseline + RevIN |
| `+inception` | + Inception | baseline + Inception Block |
| `+decomp` | + åˆ†è§£ (DFT) | baseline + DFT å­£èŠ‚-è¶‹åŠ¿åˆ†è§£ |
| `+decomp_ma` | + åˆ†è§£ (MA) | baseline + Moving Avg åˆ†è§£ |
| `+stacked` | + 2 å±‚å †å  | baseline + å¤šå±‚å †å  (2å±‚) |
| `+stacked3` | + 3 å±‚å †å  | baseline + å¤šå±‚å †å  (3å±‚) |
| `+revin+inception` | ç»„åˆé…ç½® | RevIN + Inception |
| `+revin+decomp` | ç»„åˆé…ç½® | RevIN + åˆ†è§£ |
| `+revin+stacked` | ç»„åˆé…ç½® | RevIN + å †å  |
| **`full`** | **å®Œæ•´æ¨¡å‹** | **æ‰€æœ‰æ”¹è¿›** |

### é…ç½®æ•°æ®ç»“æ„

```python
@dataclass
class AblationConfig:
    # æ¶ˆèå¼€å…³
    use_revin: bool = False           # RevIN å½’ä¸€åŒ–
    use_inception: bool = False       # Inception Block
    use_decomp: bool = False          # å­£èŠ‚-è¶‹åŠ¿åˆ†è§£
    decomp_method: str = "dft"        # åˆ†è§£æ–¹æ³•: "dft" æˆ– "moving_avg"
    use_stacked: bool = False         # å¤šå±‚å †å 
    e_layers: int = 2                 # å †å å±‚æ•°
    
    # æ¨¡å‹è¶…å‚æ•°
    hidden_dim: int = 64
    num_scales: int = 2
    top_k_periods: int = 3
    dropout: float = 0.1
```

---

## å®éªŒç»“æœ

### å·²å®Œæˆçš„æ¶ˆèå®éªŒç»“æœ (ä» `ablation/results/` ç›®å½•)

æ ¹æ®ç°æœ‰ç»“æœæ–‡ä»¶ï¼š

| å®éªŒé…ç½® | æ—¶é—´æˆ³ | çŠ¶æ€ |
|---------|--------|------|
| `baseline` | 20260125_231747 | âŒ ä¸­æ–­ (æ—  metrics) |
| `baseline` | 20260125_232154 | âœ… å®Œæˆ |
| `baseline` | 20260125_232234 | âœ… å®Œæˆ |
| `baseline` | 20260126_001459 | âœ… å®Œæˆ |
| `+revin` | 20260125_232351 | âœ… å®Œæˆ |
| `+decomp` | 20260125_232516 | âœ… å®Œæˆ |
| `full` | 20260126_002659 | âœ… å®Œæˆ |

### æ€§èƒ½å¯¹æ¯” (ç¤ºä¾‹ï¼Œéœ€è¦å®é™…è¿è¡Œè·å–)

```
é¢„æœŸç»“æœæ ¼å¼ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ é…ç½®         â”‚ MAE     â”‚ RMSE     â”‚ å‚æ•°é‡   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ baseline     â”‚ 0.7500  â”‚ 0.9500   â”‚ 150K     â”‚
â”‚ +revin       â”‚ 0.7200  â”‚ 0.9200   â”‚ 150K     â”‚
â”‚ +inception   â”‚ 0.7100  â”‚ 0.9000   â”‚ 180K     â”‚
â”‚ +decomp      â”‚ 0.7300  â”‚ 0.9300   â”‚ 160K     â”‚
â”‚ +stacked     â”‚ 0.7000  â”‚ 0.8900   â”‚ 300K     â”‚
â”‚ full         â”‚ 0.6800  â”‚ 0.8700   â”‚ 350K     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## å¦‚ä½•è¿è¡Œ

### æ–¹å¼ 1: å‘½ä»¤è¡Œè¿è¡Œå•ä¸ªé…ç½®

```bash
# æ¿€æ´»ç¯å¢ƒ
conda activate TPLC_Net

# è¿›å…¥æ¶ˆèå®éªŒç›®å½•
cd D:\degree_code_scheme_1\scheme_1\TPLC_Net\ablation

# è¿è¡ŒåŸºçº¿æ¨¡å‹
python run_ablation.py --config baseline --epochs 20

# è¿è¡Œ + RevIN
python run_ablation.py --config +revin --epochs 20

# è¿è¡Œå®Œæ•´æ¨¡å‹
python run_ablation.py --config full --epochs 20
```

### æ–¹å¼ 2: è¿è¡Œæ‰€æœ‰é…ç½®

```bash
python run_ablation.py --config all --epochs 20
```

è¿™ä¼šä¾æ¬¡è¿è¡Œæ‰€æœ‰é¢„å®šä¹‰é…ç½®ã€‚

### æ–¹å¼ 3: VS Code ä»»åŠ¡

å·²é…ç½®çš„ä»»åŠ¡ï¼ˆåœ¨ `.vscode/tasks.json` ä¸­ï¼‰ï¼š

1. `è¿è¡Œæ¶ˆèå®éªŒ (baseline)` - è¿è¡ŒåŸºçº¿
2. `è¿è¡Œæ¶ˆèå®éªŒ (full)` - è¿è¡Œå®Œæ•´æ¨¡å‹
3. `è¿è¡Œæ‰€æœ‰æ¶ˆèå®éªŒ` - æ‰¹é‡è¿è¡Œ
4. `è¿è¡Œè‡ªå®šä¹‰æ¶ˆèå®éªŒ` - è‡ªå®šä¹‰é…ç½®

ä½¿ç”¨æ–¹æ³•ï¼š
- `Ctrl+Shift+P` â†’ `Tasks: Run Task`
- é€‰æ‹©å¯¹åº”ä»»åŠ¡

### æ–¹å¼ 4: Notebook è¿è¡Œ

ä½¿ç”¨ `run_ablation_notebook.ipynb`ï¼Œå¯äº¤äº’å¼è¿è¡Œå’Œåˆ†æã€‚

---

## è¿›ä¸€æ­¥æ”¹è¿›å»ºè®®

### ğŸ¯ ä¼˜å…ˆçº§ 1ï¼šå¿…åšå®éªŒ

#### 1. **å®Œæ•´çš„æ¶ˆèå®éªŒå¯¹æ¯”**
**ç›®æ ‡**ï¼šé‡åŒ–æ¯ä¸ªç»„ä»¶çš„è´¡çŒ®

```bash
# è¿è¡Œå®Œæ•´æ¶ˆèå®éªŒ
python run_ablation.py --config all --epochs 20 --seeds 42 123 456
```

**é¢„æœŸè¾“å‡º**ï¼š
- å„é…ç½®çš„æ€§èƒ½è¡¨æ ¼
- å¯è§†åŒ–å¯¹æ¯”å›¾
- ç»„ä»¶è´¡çŒ®åˆ†æ

#### 2. **å¤šç§å­éªŒè¯**
**ç›®æ ‡**ï¼šç¡®ä¿ç»“æœç¨³å®šæ€§

```bash
# å¯¹å…³é”®é…ç½®è¿è¡Œå¤šä¸ªç§å­
for config in baseline +revin full; do
    python run_ablation.py --config $config --epochs 20 \
        --seeds 42 123 456 789 2024
done
```

### ğŸ”¬ ä¼˜å…ˆçº§ 2ï¼šæ¢ç´¢æ€§æ”¹è¿›

#### 3. **æ³¨æ„åŠ›æœºåˆ¶ä¼˜åŒ–**
å½“å‰ä½¿ç”¨ç®€å•çš„ Softmax æƒé‡ï¼Œå¯ä»¥å°è¯•ï¼š

```python
# åœ¨ tplc_model.py ä¸­æ·»åŠ 
class AdaptiveScaleAttention(nn.Module):
    """è‡ªé€‚åº”å°ºåº¦æ³¨æ„åŠ›"""
    def __init__(self, num_scales, hidden_dim):
        super().__init__()
        self.attention = nn.Sequential(
            nn.Linear(hidden_dim, num_scales),
            nn.Softmax(dim=-1)
        )
```

#### 4. **æ›´å¼ºçš„æ—¶é—´å»ºæ¨¡**
å‚è€ƒ TimeMixer/Mamba çš„æ—¶é—´æ··åˆæœºåˆ¶ï¼š

```python
# æ·»åŠ æ—¶é—´æ··åˆå±‚
class TemporalMixing(nn.Module):
    def __init__(self, seq_len, hidden_dim):
        super().__init__()
        self.mix = nn.Linear(seq_len, seq_len)
    
    def forward(self, x):
        # x: [B, C, T]
        x_t = x.transpose(1, 2)  # [B, T, C]
        mixed = self.mix(x_t.transpose(1, 2))  # æ—¶é—´ç»´æ··åˆ
        return mixed
```

#### 5. **é¢‘åŸŸå¢å¼º**
å½“å‰åªç”¨ FFT æå–å‘¨æœŸï¼Œå¯ä»¥è€ƒè™‘ï¼š

```python
# é¢‘åŸŸç‰¹å¾å¢å¼º
class FrequencyEnhancement(nn.Module):
    def __init__(self, seq_len):
        super().__init__()
        self.freq_weight = nn.Parameter(torch.ones(seq_len // 2 + 1))
    
    def forward(self, x):
        # FFT
        x_fft = torch.fft.rfft(x, dim=-1)
        # åŠ æƒ
        x_fft = x_fft * self.freq_weight
        # IFFT
        return torch.fft.irfft(x_fft, n=x.size(-1), dim=-1)
```

### ğŸ“Š ä¼˜å…ˆçº§ 3ï¼šè¶…å‚æ•°ä¼˜åŒ–

#### 6. **ç½‘æ ¼æœç´¢å…³é”®è¶…å‚æ•°**

```python
# åœ¨ run_ablation.py ä¸­æ·»åŠ 
param_grid = {
    'hidden_dim': [32, 64, 128],
    'num_scales': [1, 2, 3],
    'top_k_periods': [3, 5, 7],
    'dropout': [0.0, 0.1, 0.2],
}

# è¿è¡Œç½‘æ ¼æœç´¢
for hidden_dim in [32, 64, 128]:
    for num_scales in [1, 2, 3]:
        cfg = AblationConfig(
            name=f"grid_h{hidden_dim}_s{num_scales}",
            hidden_dim=hidden_dim,
            num_scales=num_scales
        )
        run_experiment(cfg)
```

#### 7. **å­¦ä¹ ç‡è°ƒä¼˜**

```python
# æµ‹è¯•ä¸åŒå­¦ä¹ ç‡
for lr in [1e-4, 5e-4, 1e-3, 5e-3]:
    python run_ablation.py --config full --lr $lr
```

---

## æ¶ˆèå®éªŒæœ€ä½³å®è·µ

### âœ… æ¨èåšæ³•

1. **å•å˜é‡åŸåˆ™**ï¼šæ¯æ¬¡åªæ”¹å˜ä¸€ä¸ªç»„ä»¶
2. **å¤šæ¬¡è¿è¡Œ**ï¼šæ¯ä¸ªé…ç½®è‡³å°‘ 3-5 ä¸ªéšæœºç§å­
3. **ç»Ÿä¸€é…ç½®**ï¼šæ•°æ®é›†ã€è®­ç»ƒè½®æ•°ã€batch size ä¿æŒä¸€è‡´
4. **è¯¦ç»†è®°å½•**ï¼šä¿å­˜é…ç½®ã€æŒ‡æ ‡ã€è®­ç»ƒæ›²çº¿
5. **å¯è§†åŒ–å¯¹æ¯”**ï¼šæŸ±çŠ¶å›¾ã€æŠ˜çº¿å›¾ã€é›·è¾¾å›¾

### âŒ å¸¸è§é”™è¯¯

1. âŒ åŒæ—¶æ”¹å˜å¤šä¸ªç»„ä»¶ â†’ æ— æ³•åˆ¤æ–­å“ªä¸ªæœ‰æ•ˆ
2. âŒ åªè¿è¡Œä¸€æ¬¡ â†’ ç»“æœä¸ç¨³å®š
3. âŒ ä¸åŒé…ç½®ç”¨ä¸åŒæ•°æ®/è®­ç»ƒè®¾ç½® â†’ ä¸å…¬å¹³å¯¹æ¯”
4. âŒ åªçœ‹æœ€ç»ˆæŒ‡æ ‡ï¼Œä¸çœ‹è®­ç»ƒæ›²çº¿ â†’ å¯èƒ½é—æ¼é‡è¦ä¿¡æ¯

---

## å¿«é€Ÿå¼€å§‹ï¼šå®Œæ•´æ¶ˆèå®éªŒæµç¨‹

### Step 1: å‡†å¤‡æ•°æ®
```bash
# ç¡®ä¿æ•°æ®é›†å·²å‡†å¤‡
ls D:\degree_code_scheme_1\scheme_1\datasets\è‡ªä¸»æ¸©å®¤æŒ‘æˆ˜èµ›\AICU
```

### Step 2: è¿è¡ŒåŸºçº¿æ¨¡å‹
```bash
cd D:\degree_code_scheme_1\scheme_1\TPLC_Net\ablation
conda activate TPLC_Net

# åŸºçº¿ï¼šä¸åŠ ä»»ä½•æ”¹è¿›ï¼ˆä»…æ ¸å¿ƒæ¶æ„ + Dropout + æ®‹å·®ï¼‰
python run_ablation.py --config baseline --epochs 20
```

### Step 3: é€æ­¥æ·»åŠ æ”¹è¿›
```bash
# + RevIN
python run_ablation.py --config +revin --epochs 20

# + Inception
python run_ablation.py --config +inception --epochs 20

# + åˆ†è§£
python run_ablation.py --config +decomp --epochs 20

# + å †å 
python run_ablation.py --config +stacked --epochs 20
```

### Step 4: å®Œæ•´æ¨¡å‹
```bash
# æ‰€æœ‰æ”¹è¿›
python run_ablation.py --config full --epochs 20
```

### Step 5: åˆ†æç»“æœ
```python
# åœ¨ Python ä¸­
from ablation_analysis import collect_results, plot_comparison

results = collect_results('ablation/results')
plot_comparison(results, save_path='ablation_comparison.png')
```

---

## ç»“è®ºä¸å»ºè®®

### å½“å‰çŠ¶æ€æ€»ç»“

âœ… **ä½ å·²ç»åœ¨ç”¨æ”¹è¿›åçš„æ¨¡å‹**ï¼š
- åŒ…å« Dropoutã€æ®‹å·®è¿æ¥ã€è®­ç»ƒç¨³å®šæ€§é…ç½®
- æ€§èƒ½å·²ç»æ¯”çº¯åŸºçº¿æœ‰æå‡

### ä¸‹ä¸€æ­¥è¡ŒåŠ¨

#### ç«‹å³æ‰§è¡Œ
1. **å®Œæ•´æ¶ˆèå®éªŒ**ï¼šè¿è¡Œ `python run_ablation.py --config all`
2. **å¤šç§å­éªŒè¯**ï¼šæ¯ä¸ªé…ç½®è·‘ 3-5 ä¸ªç§å­
3. **ç»“æœåˆ†æ**ï¼šç”Ÿæˆå¯¹æ¯”è¡¨å’Œå›¾è¡¨

#### ä¸­æœŸè®¡åˆ’
4. å°è¯• **é¢‘åŸŸå¢å¼º** æˆ– **è‡ªé€‚åº”æ³¨æ„åŠ›**
5. è¿›è¡Œ **è¶…å‚æ•°ç½‘æ ¼æœç´¢**
6. ä¸æœ€æ–° SOTA æ¨¡å‹ï¼ˆå¦‚ TimeMixer++, iTransformerï¼‰å¯¹æ¯”

#### é•¿æœŸä¼˜åŒ–
7. æ¢ç´¢ **Mamba/State Space Models**
8. åŠ å…¥ **Fourier Neural Operator**
9. ç ”ç©¶ **å¤šä»»åŠ¡å­¦ä¹ **ï¼ˆåŒæ—¶é¢„æµ‹å¤šä¸ªç›®æ ‡ï¼‰

---

## å‚è€ƒèµ„æ–™

### ç›¸å…³æ–‡ä»¶
- ä¸»æ¨¡å‹ä»£ç : `tplc_algo/models/tplc_model.py`
- æ¶ˆèå®éªŒè„šæœ¬: `ablation/run_ablation.py`
- å¯¹æ¯”å®éªŒ Notebook: `run_compare_experiment.ipynb`
- ç»Ÿä¸€å¯¹æ¯”è„šæœ¬: `run_all_baselines.py`

### è®ºæ–‡å‚è€ƒ
1. **TimesNet**: "TimesNet: Temporal 2D-Variation Modeling for General Time Series Analysis" (ICLR 2023)
2. **RevIN**: "Reversible Instance Normalization for Accurate Time-Series Forecasting" (ICLR 2022)
3. **Inception**: "Going Deeper with Convolutions" (CVPR 2015)
4. **æ®‹å·®ç½‘ç»œ**: "Deep Residual Learning for Image Recognition" (CVPR 2016)

### æœ‰ç”¨çš„æ¶ˆèå®éªŒä¾‹å­
- PatchTST è®ºæ–‡çš„ Table 3: Ablation Study
- TimesNet è®ºæ–‡çš„ Table 5: Module Analysis
- iTransformer è®ºæ–‡çš„ Table 6: Component Analysis

---

## FAQ

### Q1: baseline é…ç½®åŒ…å«å“ªäº›æ”¹è¿›ï¼Ÿ
**A**: åŒ…å«æ ¸å¿ƒæ¶æ„ + Dropout + æ®‹å·®è¿æ¥ã€‚è¿™äº›æ˜¯"åŸºç¡€ç¨³å®šæ€§"æ”¹è¿›ï¼Œä¸ç®—æ¶ˆèå¯¹è±¡ã€‚

### Q2: ä¸ºä»€ä¹ˆæ”¹è¿›ååè€Œå˜å·®äº†ï¼Ÿ
**A**: å¯èƒ½åŸå› ï¼š
1. è¶…å‚æ•°ä¸åŒ¹é…ï¼ˆéœ€è¦é‡æ–°è°ƒå‚ï¼‰
2. æ•°æ®é›†ä¸é€‚åˆè¯¥æ”¹è¿›
3. å®ç°æœ‰ bug
4. éšæœºæ€§æ³¢åŠ¨ï¼ˆå¤šè·‘å‡ æ¬¡ï¼‰

### Q3: å¦‚ä½•é€‰æ‹©æœ€ä¼˜é…ç½®ï¼Ÿ
**A**: ç»¼åˆè€ƒè™‘ï¼š
1. **æ€§èƒ½** (MAE, RMSE)
2. **æ•ˆç‡** (å‚æ•°é‡, è®­ç»ƒæ—¶é—´)
3. **ç¨³å®šæ€§** (å¤šç§å­æ ‡å‡†å·®)
4. **å¯è§£é‡Šæ€§**

### Q4: å¯ä»¥åŒæ—¶æµ‹è¯•å¤šä¸ªæ”¹è¿›å—ï¼Ÿ
**A**: ä¸æ¨èã€‚æ¶ˆèå®éªŒçš„æ ¸å¿ƒæ˜¯"å•å˜é‡æ§åˆ¶"ï¼ŒåŒæ—¶æ”¹å¤šä¸ªæ— æ³•åˆ¤æ–­å“ªä¸ªæœ‰æ•ˆã€‚åº”è¯¥ï¼š
1. å…ˆé€ä¸ªæµ‹è¯•
2. å†æµ‹è¯•ç»„åˆ
3. æœ€åæµ‹è¯•å…¨éƒ¨

---

## æ›´æ–°æ—¥å¿—

- **2026-01-27**: åˆ›å»ºæ–‡æ¡£ï¼Œæ•´ç†å½“å‰æ”¹è¿›çŠ¶æ€å’Œæ¶ˆèå®éªŒæŒ‡å—
- **2025-01-26**: å®Œæˆåˆæ­¥æ¶ˆèå®éªŒ (baseline, +revin, +decomp, full)
- **2025-01-25**: åœ¨ä¸»æ¨¡å‹ä¸­æ·»åŠ  Dropout å’Œæ®‹å·®è¿æ¥

---

**ç¥å®éªŒé¡ºåˆ©ï¼å¦‚æœ‰é—®é¢˜ï¼Œè¯·å‚è€ƒ `run_ablation.py` ä¸­çš„è¯¦ç»†æ³¨é‡Šã€‚** ğŸš€
