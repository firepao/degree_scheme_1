"""ç»Ÿä¸€å¯¹æ¯”å®éªŒè„šæœ¬ï¼šæ‰€æœ‰åŸºçº¿æ¨¡å‹ä½¿ç”¨ç›¸åŒé…ç½®ã€‚

åŠŸèƒ½ï¼š
1. ç»Ÿä¸€è®­ç»ƒé…ç½®ï¼ˆepochs, lr, early_stop ç­‰ï¼‰
2. æ”¯æŒå¤šéšæœºç§å­è¿è¡Œå–å¹³å‡
3. æ”¯æŒé€‰æ‹©è¦è¿è¡Œçš„æ¨¡å‹
4. è‡ªåŠ¨æ±‡æ€»ç»“æœåˆ° CSV/JSON

ä½¿ç”¨ç¤ºä¾‹ï¼š
    # è¿è¡Œæ‰€æœ‰æ¨¡å‹ï¼Œå•æ¬¡
    python run_all_baselines.py

    # è¿è¡Œæ‰€æœ‰æ¨¡å‹ï¼Œ3ä¸ªç§å­å–å¹³å‡
    python run_all_baselines.py --seeds 42 123 456

    # åªè¿è¡ŒæŒ‡å®šæ¨¡å‹
    python run_all_baselines.py --models tplcnet lstm timesnet

    # è‡ªå®šä¹‰é…ç½®
    python run_all_baselines.py --epochs 30 --lr 0.001 --pred-len 72
"""

from __future__ import annotations

import argparse
import json
import sys
from dataclasses import dataclass, field, asdict
from pathlib import Path
from typing import Any, Dict, List, Optional
from datetime import datetime

import numpy as np
import pandas as pd
import torch
from torch.utils.data import DataLoader

# æ·»åŠ è·¯å¾„
scheme_root = Path(__file__).resolve().parent
tplc_net_root = scheme_root / 'TPLC_Net'
baselines_root = scheme_root / 'baselines'

sys.path.insert(0, str(tplc_net_root))
sys.path.insert(0, str(baselines_root))

# å¯¼å…¥å·¥å…·
from tplc_algo.pipeline import prepare_greenhouse_datasets, make_loaders
from tplc_algo.train import Trainer, TrainConfig
from tplc_algo.utils import seed_everything
from tplc_algo.config import TPLCConfig
from tplc_algo.exp_utils import create_run_dir, save_json


@dataclass
class UnifiedConfig:
    """ç»Ÿä¸€å®éªŒé…ç½®"""
    # æ•°æ®
    team: str = 'AICU'
    seq_len: int = 288
    pred_len: int = 72
    stride: int = 1
    batch_size: int = 32
    
    # è®­ç»ƒï¼ˆæ‰€æœ‰æ¨¡å‹ç»Ÿä¸€ï¼‰
    epochs: int = 20
    lr: float = 1e-3
    weight_decay: float = 0.0
    
    # ç¨³å®šæ€§é…ç½®ï¼ˆæ‰€æœ‰æ¨¡å‹ç»Ÿä¸€ï¼‰
    grad_clip_max_norm: float = 1.0
    use_amp: bool = True
    lr_scheduler: str = 'plateau'
    plateau_patience: int = 3
    plateau_factor: float = 0.5
    early_stop_patience: int = 6
    
    # å®éªŒè®¾ç½®
    seeds: List[int] = field(default_factory=lambda: [42])
    models: List[str] = field(default_factory=lambda: ['tplcnet', 'lstm', 'timesnet', 'patchtst', 'timemixer', 'timemixer_pp', 'transformer', 'tritracknet'])
    
    # æ¨¡å‹ç‰¹å®šè¶…å‚æ•°ï¼ˆå¯è¦†ç›–ï¼‰
    # TPLCNet
    tplc_hidden_dim: int = 32
    tplc_top_k_periods: int = 4
    tplc_num_scales: int = 1
    
    # LSTM
    lstm_hidden_dim: int = 128
    lstm_num_layers: int = 2
    
    # TimesNet
    timesnet_d_model: int = 32
    timesnet_d_ff: int = 64
    timesnet_e_layers: int = 2
    timesnet_top_k: int = 5
    
    # PatchTST
    patchtst_d_model: int = 64
    patchtst_n_heads: int = 4
    patchtst_e_layers: int = 2
    patchtst_patch_len: int = 16
    
    # TimeMixer/TimeMixer++
    timemixer_d_model: int = 32
    timemixer_e_layers: int = 2


def load_models(cfg: UnifiedConfig, input_dim: int, target_dim: int) -> Dict[str, torch.nn.Module]:
    """æŒ‰éœ€åŠ è½½æ¨¡å‹"""
    models = {}
    
    if 'tplcnet' in cfg.models:
        from tplc_algo.models import TPLCNet
        models['tplcnet'] = lambda: TPLCNet(
            input_dim=input_dim,
            target_dim=target_dim,
            seq_len=cfg.seq_len,
            pred_len=cfg.pred_len,
            hidden_dim=cfg.tplc_hidden_dim,
            top_k_periods=cfg.tplc_top_k_periods,
            num_scales=cfg.tplc_num_scales,
        )
    
    if 'lstm' in cfg.models:
        from LSTM import LSTMForecaster
        models['lstm'] = lambda: LSTMForecaster(
            input_dim=input_dim,
            target_dim=target_dim,
            seq_len=cfg.seq_len,
            pred_len=cfg.pred_len,
            hidden_dim=cfg.lstm_hidden_dim,
            num_layers=cfg.lstm_num_layers,
            dropout=0.1,
        )
    
    if 'timesnet' in cfg.models:
        from TimesNet import TimesNetForecaster
        models['timesnet'] = lambda: TimesNetForecaster(
            input_dim=input_dim,
            target_dim=target_dim,
            seq_len=cfg.seq_len,
            pred_len=cfg.pred_len,
            d_model=cfg.timesnet_d_model,
            d_ff=cfg.timesnet_d_ff,
            e_layers=cfg.timesnet_e_layers,
            top_k=cfg.timesnet_top_k,
            num_kernels=6,
            dropout=0.1,
        )
    
    if 'patchtst' in cfg.models:
        try:
            from PatchTST import PatchTSTForecaster
            models['patchtst'] = lambda: PatchTSTForecaster(
                input_dim=input_dim,
                target_dim=target_dim,
                seq_len=cfg.seq_len,
                pred_len=cfg.pred_len,
                d_model=cfg.patchtst_d_model,
                n_heads=cfg.patchtst_n_heads,
                e_layers=cfg.patchtst_e_layers,
                d_ff=cfg.patchtst_d_model * 2,
                patch_len=cfg.patchtst_patch_len,
                stride=cfg.patchtst_patch_len // 2,
                dropout=0.1,
            )
        except ImportError as e:
            print(f"âš ï¸ PatchTST å¯¼å…¥å¤±è´¥: {e}")
    
    if 'timemixer' in cfg.models:
        try:
            from TimeMixer import TimeMixerForecaster, TimeMixerConfig
            def create_timemixer():
                tm_cfg = TimeMixerConfig(
                    seq_len=cfg.seq_len,
                    pred_len=cfg.pred_len,
                    enc_in=input_dim,
                    c_out=target_dim,
                    d_model=cfg.timemixer_d_model,
                    d_ff=cfg.timemixer_d_model * 2,
                    e_layers=cfg.timemixer_e_layers,
                    down_sampling_layers=2,
                    down_sampling_method='avg',
                    channel_independence=False,
                )
                return TimeMixerForecaster(tm_cfg)
            models['timemixer'] = create_timemixer
        except ImportError as e:
            print(f"âš ï¸ TimeMixer å¯¼å…¥å¤±è´¥: {e}")
    
    if 'timemixer_pp' in cfg.models:
        try:
            # TimeMixer++ éœ€è¦ç‰¹æ®Šå¤„ç†è·¯å¾„
            timemixer_pp_path = baselines_root / 'TimeMixer++'
            if str(timemixer_pp_path) not in sys.path:
                sys.path.append(str(timemixer_pp_path))
            from timemixer_pp_algo.model import TimeMixerPPForecaster
            from timemixer_pp_algo.config import TimeMixerPPConfig
            def create_timemixer_pp():
                tm_cfg = TimeMixerPPConfig(
                    seq_len=cfg.seq_len,
                    pred_len=cfg.pred_len,
                    enc_in=input_dim,
                    c_out=target_dim,
                    d_model=cfg.timemixer_d_model,
                    d_ff=cfg.timemixer_d_model * 2,
                    e_layers=cfg.timemixer_e_layers,
                    num_scales=2,
                    top_k=3,
                    dropout=0.1,
                    channel_independence=False,
                )
                return TimeMixerPPForecaster(tm_cfg)
            models['timemixer_pp'] = create_timemixer_pp
        except ImportError as e:
            print(f"âš ï¸ TimeMixer++ å¯¼å…¥å¤±è´¥: {e}")
    
    if 'transformer' in cfg.models:
        try:
            from Transformer import TransformerForecaster
            models['transformer'] = lambda: TransformerForecaster(
                input_dim=input_dim,
                target_dim=target_dim,
                seq_len=cfg.seq_len,
                pred_len=cfg.pred_len,
                d_model=64,
                n_heads=4,
                d_ff=128,
                e_layers=2,
                d_layers=1,
                dropout=0.1,
            )
        except ImportError as e:
            print(f"âš ï¸ Transformer å¯¼å…¥å¤±è´¥: {e}")
    
    if 'tritracknet' in cfg.models:
        try:
            # TriTrackNet éœ€è¦ç‰¹æ®Šå¤„ç†è·¯å¾„
            tritracknet_path = baselines_root / 'TriTrackNet' / 'TriTrackNet'
            if str(tritracknet_path) not in sys.path:
                sys.path.insert(0, str(tritracknet_path))
            
            from TriTrackNetWrapper import TriTrackNetWrapper
            models['tritracknet'] = lambda: TriTrackNetWrapper(
                input_dim=input_dim,
                target_dim=target_dim,
                seq_len=cfg.seq_len,
                pred_len=cfg.pred_len,
            )
        except ImportError as e:
            print(f"âš ï¸ TriTrackNet å¯¼å…¥å¤±è´¥: {e}")
    
    return models


@torch.no_grad()
def compute_raw_metrics(model, loader, device, target_scaler, target_dim) -> Dict[str, float]:
    """è®¡ç®—åæ ‡å‡†åŒ–åçš„æŒ‡æ ‡"""
    model.eval()
    y_true_list, y_pred_list = [], []
    
    for x, y in loader:
        x = x.to(device)
        y_hat = model(x).cpu().numpy()
        y_true_list.append(y.numpy())
        y_pred_list.append(y_hat)
    
    y_true = np.concatenate(y_true_list, axis=0)
    y_pred = np.concatenate(y_pred_list, axis=0)
    
    y_true_raw = target_scaler.inverse_transform(y_true.reshape(-1, target_dim)).reshape(y_true.shape)
    y_pred_raw = target_scaler.inverse_transform(y_pred.reshape(-1, target_dim)).reshape(y_pred.shape)
    
    return {
        'mae_raw': float(np.mean(np.abs(y_true_raw - y_pred_raw))),
        'rmse_raw': float(np.sqrt(np.mean((y_true_raw - y_pred_raw) ** 2))),
    }


def train_single_model(
    model_name: str,
    model: torch.nn.Module,
    cfg: UnifiedConfig,
    train_loader: DataLoader,
    val_loader: DataLoader,
    test_loader: DataLoader,
    target_scaler,
    target_dim: int,
    run_dir: Path,
    seed: int,
) -> Dict[str, Any]:
    """è®­ç»ƒå¹¶è¯„ä¼°å•ä¸ªæ¨¡å‹"""
    import time
    
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    # è®¡ç®—æ¨¡å‹å‚æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    model_dir = run_dir / model_name / f'seed_{seed}'
    model_dir.mkdir(parents=True, exist_ok=True)
    ckpt_path = model_dir / 'best.pt'
    
    trainer = Trainer(
        model=model,
        cfg=TrainConfig(
            epochs=cfg.epochs,
            lr=cfg.lr,
            weight_decay=cfg.weight_decay,
            device=device,
            ckpt_path=ckpt_path,
            grad_clip_max_norm=cfg.grad_clip_max_norm,
            use_amp=cfg.use_amp and device == 'cuda',
            lr_scheduler=cfg.lr_scheduler,
            plateau_patience=cfg.plateau_patience,
            plateau_factor=cfg.plateau_factor,
            early_stop_patience=cfg.early_stop_patience,
            show_progress=True,
            progress_granularity='epoch',
        ),
    )
    
    # è®°å½•è®­ç»ƒæ—¶é—´
    start_time = time.time()
    history = trainer.fit(train_loader, val_loader=val_loader)
    train_time = time.time() - start_time
    
    metrics = trainer.evaluate(test_loader)
    
    # è®¡ç®—åŸå§‹å°ºåº¦æŒ‡æ ‡
    raw_metrics = compute_raw_metrics(model, test_loader, device, target_scaler, target_dim)
    metrics.update(raw_metrics)
    
    # æ·»åŠ å‚æ•°é‡å’Œè®­ç»ƒæ—¶é—´
    metrics['total_params'] = total_params
    metrics['trainable_params'] = trainable_params
    metrics['train_time'] = train_time
    
    # ä¿å­˜
    save_json(model_dir / 'metrics.json', metrics)
    save_json(model_dir / 'history.json', history)
    
    print(f"  ğŸ“Š {model_name} (seed={seed}): MAE={metrics['mae']:.4f}, å‚æ•°={trainable_params/1e3:.1f}K, è€—æ—¶={train_time:.1f}s")
    
    return {
        'model': model_name,
        'seed': seed,
        **metrics,
    }


def run_experiment(cfg: UnifiedConfig) -> pd.DataFrame:
    """è¿è¡Œå®Œæ•´å®éªŒ"""
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"\n{'='*60}")
    print(f"ç»Ÿä¸€å¯¹æ¯”å®éªŒ")
    print(f"{'='*60}")
    print(f"è®¾å¤‡: {device}")
    print(f"æ¨¡å‹: {cfg.models}")
    print(f"éšæœºç§å­: {cfg.seeds}")
    print(f"è®­ç»ƒé…ç½®: epochs={cfg.epochs}, lr={cfg.lr}, early_stop={cfg.early_stop_patience}")
    print(f"{'='*60}\n")
    
    # åˆ›å»ºå®éªŒç›®å½•
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    run_dir = create_run_dir(
        f'unified_compare_{cfg.team}_{timestamp}',
        base_dir=scheme_root / 'compare_result'
    )
    print(f"å®éªŒç›®å½•: {run_dir}\n")
    
    # ä¿å­˜é…ç½®
    save_json(run_dir / 'config.json', asdict(cfg))
    
    # å‡†å¤‡æ•°æ®ï¼ˆåªéœ€ä¸€æ¬¡ï¼‰
    dataset_root = scheme_root / 'datasets' / 'è‡ªä¸»æ¸©å®¤æŒ‘æˆ˜èµ›'
    selected_features = list(TPLCConfig.feature_cols) if TPLCConfig.feature_cols else None
    target_cols_cfg = list(TPLCConfig.target_cols) if TPLCConfig.target_cols else None
    
    print(f"åŠ è½½æ•°æ®: {dataset_root / cfg.team}")
    if selected_features:
        print(f"è¾“å…¥ç‰¹å¾: {len(selected_features)} ä¸ª")
    if target_cols_cfg:
        print(f"ç›®æ ‡å˜é‡: {target_cols_cfg}")
    
    prepared = prepare_greenhouse_datasets(
        dataset_root=dataset_root,
        team=cfg.team,
        seq_len=cfg.seq_len,
        pred_len=cfg.pred_len,
        stride=cfg.stride,
        selected_features=selected_features,
        target_cols=target_cols_cfg,
        missing_rate_threshold=0.7,
        drop_constant=True,
        protect_target_cols=True,
    )
    
    input_dim = len(prepared.feature_cols)
    target_dim = len(prepared.target_cols)
    print(f"Input dim: {input_dim}, Target dim: {target_dim}")
    
    train_loader, val_loader, test_loader = make_loaders(prepared, batch_size=cfg.batch_size)
    print(f"Train: {len(train_loader)} batches, Val: {len(val_loader)}, Test: {len(test_loader)}\n")
    
    # åŠ è½½æ¨¡å‹å·¥å‚
    model_factories = load_models(cfg, input_dim, target_dim)
    
    # è¿è¡Œå®éªŒ
    all_results = []
    
    for model_name in cfg.models:
        if model_name not in model_factories:
            print(f"âš ï¸ è·³è¿‡ {model_name}ï¼ˆæœªæ‰¾åˆ°æˆ–å¯¼å…¥å¤±è´¥ï¼‰")
            continue
        
        for seed in cfg.seeds:
            print(f"\n{'='*40}")
            print(f"è®­ç»ƒ {model_name} (seed={seed})")
            print(f"{'='*40}")
            
            seed_everything(seed)
            
            # åˆ›å»ºæ–°æ¨¡å‹å®ä¾‹
            model = model_factories[model_name]()
            param_count = sum(p.numel() for p in model.parameters() if p.requires_grad)
            print(f"å‚æ•°é‡: {param_count:,}")
            
            result = train_single_model(
                model_name=model_name,
                model=model,
                cfg=cfg,
                train_loader=train_loader,
                val_loader=val_loader,
                test_loader=test_loader,
                target_scaler=prepared.target_scaler,
                target_dim=target_dim,
                run_dir=run_dir,
                seed=seed,
            )
            all_results.append(result)
            
            print(f"âœ… {model_name} (seed={seed}): MAE_raw={result['mae_raw']:.4f}, RMSE_raw={result['rmse_raw']:.4f}")
    
    # æ±‡æ€»ç»“æœ
    results_df = pd.DataFrame(all_results)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ç»“æœ
    if len(results_df) == 0:
        print("\nâŒ æ²¡æœ‰æ¨¡å‹æˆåŠŸè¿è¡Œï¼Œè¯·æ£€æŸ¥æ¨¡å‹å¯¼å…¥å’Œé…ç½®ï¼")
        return None
    
    # æŒ‰æ¨¡å‹èšåˆï¼ˆå¤šç§å­å–å¹³å‡ï¼‰
    if len(cfg.seeds) > 1:
        summary_df = results_df.groupby('model').agg({
            'loss': ['mean', 'std'],
            'mae': ['mean', 'std'],
            'rmse': ['mean', 'std'],
            'mae_raw': ['mean', 'std'],
            'rmse_raw': ['mean', 'std'],
        }).round(4)
        summary_df.columns = ['_'.join(col) for col in summary_df.columns]
        summary_df = summary_df.reset_index()
    else:
        summary_df = results_df[['model', 'loss', 'mae', 'rmse', 'mae_raw', 'rmse_raw']].round(4)
    
    # ä¿å­˜ç»“æœ
    results_df.to_csv(run_dir / 'all_results.csv', index=False, encoding='utf-8-sig')
    summary_df.to_csv(run_dir / 'summary.csv', index=False, encoding='utf-8-sig')
    
    print(f"\n{'='*60}")
    print("å®éªŒå®Œæˆï¼æ±‡æ€»ç»“æœï¼š")
    print(f"{'='*60}")
    print(summary_df.to_string(index=False))
    print(f"\nç»“æœä¿å­˜è‡³: {run_dir}")
    
    return summary_df


def parse_args():
    parser = argparse.ArgumentParser(description='ç»Ÿä¸€å¯¹æ¯”å®éªŒ')
    
    # æ•°æ®é…ç½®
    parser.add_argument('--team', type=str, default='AICU')
    parser.add_argument('--seq-len', type=int, default=288)
    parser.add_argument('--pred-len', type=int, default=72)
    parser.add_argument('--batch-size', type=int, default=32)
    
    # è®­ç»ƒé…ç½®
    parser.add_argument('--epochs', type=int, default=20)
    parser.add_argument('--lr', type=float, default=1e-3)
    parser.add_argument('--early-stop', type=int, default=6)
    
    # å®éªŒé…ç½®
    parser.add_argument('--seeds', type=int, nargs='+', default=[42],
                        help='éšæœºç§å­åˆ—è¡¨ï¼Œå¦‚ --seeds 42 123 456')
    parser.add_argument('--models', type=str, nargs='+', 
                        default=['tplcnet', 'lstm', 'timesnet'],
                        help='è¦è¿è¡Œçš„æ¨¡å‹ï¼Œå¦‚ --models tplcnet lstm timesnet patchtst')
    
    return parser.parse_args()


def main():
    args = parse_args()
    
    cfg = UnifiedConfig(
        team=args.team,
        seq_len=args.seq_len,
        pred_len=args.pred_len,
        batch_size=args.batch_size,
        epochs=args.epochs,
        lr=args.lr,
        early_stop_patience=args.early_stop,
        seeds=args.seeds,
        models=args.models,
    )
    
    run_experiment(cfg)


if __name__ == '__main__':
    main()
